{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Lasso Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self, learning_rate=0.01, iterations=1000, l2_penalty=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.l2_penalty = l2_penalty\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.m, self.n = X.shape\n",
    "        self.X = np.insert(X, 0, 1, axis=1)  # Add a column of ones for the intercept term\n",
    "        self.y = y\n",
    "        self.theta = np.zeros(self.n + 1)  # Initialize coefficients\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            self.gradient_descent()\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        predictions = self.predict(self.X)\n",
    "        errors = predictions - self.y\n",
    "        \n",
    "        gradient = (1/self.m) * np.dot(self.X.T, errors) + (self.l2_penalty / self.m) * self.theta\n",
    "        gradient[0] -= (self.l2_penalty / self.m) * self.theta[0]  # Intercept term should not be regularized\n",
    "        \n",
    "        self.theta -= self.learning_rate * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.insert(X, 0, 1, axis=1)  # Add a column of ones for the intercept term\n",
    "        return np.dot(X, self.theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Ridge Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self, learning_rate=0.01, iterations=1000, l2_penalty=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.l2_penalty = l2_penalty\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.m, self.n = X.shape\n",
    "        self.X = np.insert(X, 0, 1, axis=1)  # Add a column of ones for the intercept term\n",
    "        self.y = y\n",
    "        self.theta = np.zeros(self.n + 1)  # Initialize coefficients\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            self.gradient_descent()\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        predictions = self.predict(self.X)\n",
    "        errors = predictions - self.y\n",
    "        \n",
    "        gradient = (1/self.m) * np.dot(self.X.T, errors) + (self.l2_penalty / self.m) * self.theta\n",
    "        gradient[0] -= (self.l2_penalty / self.m) * self.theta[0]  # Intercept term should not be regularized\n",
    "        \n",
    "        self.theta -= self.learning_rate * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.insert(X, 0, 1, axis=1)  # Add a column of ones for the intercept term\n",
    "        return np.dot(X, self.theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Ridge Classifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeClassifier:\n",
    "    def __init__(self, learning_rate=0.01, iterations=1000, l2_penalty=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.l2_penalty = l2_penalty\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.m, self.n = X.shape\n",
    "        self.X = np.insert(X, 0, 1, axis=1)  # Add a column of ones for the intercept term\n",
    "        self.y = y\n",
    "        self.theta = np.zeros(self.n + 1)  # Initialize coefficients\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            self.gradient_descent()\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        predictions = self.sigmoid(self.predict(self.X))\n",
    "        errors = predictions - self.y\n",
    "        \n",
    "        gradient = (1/self.m) * np.dot(self.X.T, errors) + (self.l2_penalty / self.m) * self.theta\n",
    "        gradient[0] -= (self.l2_penalty / self.m) * self.theta[0]  # Intercept term should not be regularized\n",
    "        \n",
    "        self.theta -= self.learning_rate * gradient\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.insert(X, 0, 1, axis=1)  # Add a column of ones for the intercept term\n",
    "        return np.dot(X, self.theta)\n",
    "\n",
    "    def predict_classes(self, X, threshold=0.5):\n",
    "        probabilities = self.sigmoid(self.predict(X))\n",
    "        return [1 if p >= threshold else 0 for p in probabilities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (100,5) and (4,) not aligned: 5 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create and fit the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m RidgeRegression(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, l2_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     11\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m, in \u001b[0;36mRidgeRegression.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Initialize coefficients\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mRidgeRegression.gradient_descent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient_descent\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     errors \u001b[38;5;241m=\u001b[39m predictions \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my\n\u001b[0;32m     20\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mT, errors) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2_penalty \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta\n",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m, in \u001b[0;36mRidgeRegression.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m     26\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(X, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add a column of ones for the intercept term\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (100,5) and (4,) not aligned: 5 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(100, 3)\n",
    "y = 2.5 * X[:, 0] + 1.5 * X[:, 1] - 3.0 * X[:, 2] + np.random.randn(100)\n",
    "\n",
    "# Create and fit the model\n",
    "model = RidgeRegression(learning_rate=0.01, iterations=1000, l2_penalty=0.1)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "print(\"Coefficients:\", model.theta)\n",
    "print(\"Predictions:\", predictions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
